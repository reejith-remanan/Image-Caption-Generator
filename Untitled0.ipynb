{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMsAaNhtMqE09g4JSGPnCdD"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LiHaFua36BiI","executionInfo":{"status":"ok","timestamp":1683105583987,"user_tz":-330,"elapsed":21147,"user":{"displayName":"Joel Kunjachan Varghese","userId":"13276675938730244655"}},"outputId":"db8087b6-3e40-42dc-d7ab-82fbfd4af4a5"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["%cd \"/content/drive/MyDrive/image_caption\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jPI8Gnyl6G3C","executionInfo":{"status":"ok","timestamp":1683105583988,"user_tz":-330,"elapsed":8,"user":{"displayName":"Joel Kunjachan Varghese","userId":"13276675938730244655"}},"outputId":"146d8262-01fc-4bcb-942a-bf78e1929af8"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/image_caption\n"]}]},{"cell_type":"code","source":["!apt install --allow-change-held-packages libcudnn8=8.1.0.77-1+cuda11.2"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gkI2ZyY16Gzp","executionInfo":{"status":"ok","timestamp":1683105829076,"user_tz":-330,"elapsed":67890,"user":{"displayName":"Joel Kunjachan Varghese","userId":"13276675938730244655"}},"outputId":"d60c7bdd-9300-42e2-e7df-9017692dcdc2"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Reading package lists... Done\n","Building dependency tree       \n","Reading state information... Done\n","The following packages will be REMOVED:\n","  libcudnn8-dev\n","The following held packages will be changed:\n","  libcudnn8\n","The following packages will be DOWNGRADED:\n","  libcudnn8\n","0 upgraded, 0 newly installed, 1 downgraded, 1 to remove and 22 not upgraded.\n","Need to get 430 MB of archives.\n","After this operation, 1,153 MB disk space will be freed.\n","Get:1 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64  libcudnn8 8.1.0.77-1+cuda11.2 [430 MB]\n","Fetched 430 MB in 6s (71.5 MB/s)\n","(Reading database ... 122518 files and directories currently installed.)\n","Removing libcudnn8-dev (8.7.0.84-1+cuda11.8) ...\n","update-alternatives: removing manually selected alternative - switching libcudnn to auto mode\n","\u001b[1mdpkg:\u001b[0m \u001b[1;33mwarning:\u001b[0m downgrading libcudnn8 from 8.7.0.84-1+cuda11.8 to 8.1.0.77-1+cuda11.2\n","(Reading database ... 122485 files and directories currently installed.)\n","Preparing to unpack .../libcudnn8_8.1.0.77-1+cuda11.2_amd64.deb ...\n","Unpacking libcudnn8 (8.1.0.77-1+cuda11.2) over (8.7.0.84-1+cuda11.8) ...\n","Setting up libcudnn8 (8.1.0.77-1+cuda11.2) ...\n"]}]},{"cell_type":"code","source":["!pip uninstall -y tensorflow estimator keras tensorflow-metadata protobuf"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jCGzofKM6pYc","executionInfo":{"status":"ok","timestamp":1683105858677,"user_tz":-330,"elapsed":29605,"user":{"displayName":"Joel Kunjachan Varghese","userId":"13276675938730244655"}},"outputId":"662951e1-189e-4f11-a21d-52f5c33cf46b"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Found existing installation: tensorflow 2.12.0\n","Uninstalling tensorflow-2.12.0:\n","  Successfully uninstalled tensorflow-2.12.0\n","\u001b[33mWARNING: Skipping estimator as it is not installed.\u001b[0m\u001b[33m\n","\u001b[0mFound existing installation: keras 2.12.0\n","Uninstalling keras-2.12.0:\n","  Successfully uninstalled keras-2.12.0\n","Found existing installation: tensorflow-metadata 1.13.1\n","Uninstalling tensorflow-metadata-1.13.1:\n","  Successfully uninstalled tensorflow-metadata-1.13.1\n","Found existing installation: protobuf 3.20.3\n","Uninstalling protobuf-3.20.3:\n","  Successfully uninstalled protobuf-3.20.3\n"]}]},{"cell_type":"code","source":["!pip install tensorflow-text==2.11.0"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WjboADfF6pU4","executionInfo":{"status":"ok","timestamp":1683105918067,"user_tz":-330,"elapsed":59394,"user":{"displayName":"Joel Kunjachan Varghese","userId":"13276675938730244655"}},"outputId":"5cff3234-0c00-4dba-d040-e00aa3479a9a"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting tensorflow-text==2.11.0\n","  Downloading tensorflow_text-2.11.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.8/5.8 MB\u001b[0m \u001b[31m35.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting tensorflow<2.12,>=2.11.0\n","  Downloading tensorflow-2.11.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (588.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m588.3/588.3 MB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tensorflow-hub>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-text==2.11.0) (0.13.0)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow-text==2.11.0) (1.54.0)\n","Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow-text==2.11.0) (1.6.3)\n","Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow-text==2.11.0) (0.4.0)\n","Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow-text==2.11.0) (0.2.0)\n","Collecting tensorboard<2.12,>=2.11\n","  Downloading tensorboard-2.11.2-py3-none-any.whl (6.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m36.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow-text==2.11.0) (67.7.2)\n","Collecting tensorflow-estimator<2.12,>=2.11.0\n","  Downloading tensorflow_estimator-2.11.0-py2.py3-none-any.whl (439 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m439.2/439.2 kB\u001b[0m \u001b[31m20.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow-text==2.11.0) (2.3.0)\n","Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow-text==2.11.0) (1.4.0)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow-text==2.11.0) (3.3.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow-text==2.11.0) (23.1)\n","Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow-text==2.11.0) (4.5.0)\n","Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow-text==2.11.0) (16.0.0)\n","Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow-text==2.11.0) (1.22.4)\n","Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow-text==2.11.0) (0.32.0)\n","Collecting protobuf<3.20,>=3.9.2\n","  Downloading protobuf-3.19.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m27.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow-text==2.11.0) (1.14.1)\n","Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow-text==2.11.0) (23.3.3)\n","Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow-text==2.11.0) (1.16.0)\n","Collecting keras<2.12,>=2.11.0\n","  Downloading keras-2.11.0-py2.py3-none-any.whl (1.7 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m72.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow-text==2.11.0) (3.8.0)\n","Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow<2.12,>=2.11.0->tensorflow-text==2.11.0) (0.40.0)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow-text==2.11.0) (2.27.1)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow-text==2.11.0) (2.3.0)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow-text==2.11.0) (2.17.3)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow-text==2.11.0) (3.4.3)\n","Collecting google-auth-oauthlib<0.5,>=0.4.1\n","  Downloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow-text==2.11.0) (1.8.1)\n","Collecting tensorboard-data-server<0.7.0,>=0.6.0\n","  Downloading tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl (4.9 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m72.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow-text==2.11.0) (0.3.0)\n","Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow-text==2.11.0) (5.3.0)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow-text==2.11.0) (4.9)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow-text==2.11.0) (1.3.1)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow-text==2.11.0) (3.4)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow-text==2.11.0) (2.0.12)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow-text==2.11.0) (2022.12.7)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow-text==2.11.0) (1.26.15)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow-text==2.11.0) (2.1.2)\n","Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow-text==2.11.0) (0.5.0)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow-text==2.11.0) (3.2.2)\n","Installing collected packages: tensorflow-estimator, tensorboard-data-server, protobuf, keras, google-auth-oauthlib, tensorboard, tensorflow, tensorflow-text\n","  Attempting uninstall: tensorflow-estimator\n","    Found existing installation: tensorflow-estimator 2.12.0\n","    Uninstalling tensorflow-estimator-2.12.0:\n","      Successfully uninstalled tensorflow-estimator-2.12.0\n","  Attempting uninstall: tensorboard-data-server\n","    Found existing installation: tensorboard-data-server 0.7.0\n","    Uninstalling tensorboard-data-server-0.7.0:\n","      Successfully uninstalled tensorboard-data-server-0.7.0\n","  Attempting uninstall: google-auth-oauthlib\n","    Found existing installation: google-auth-oauthlib 1.0.0\n","    Uninstalling google-auth-oauthlib-1.0.0:\n","      Successfully uninstalled google-auth-oauthlib-1.0.0\n","  Attempting uninstall: tensorboard\n","    Found existing installation: tensorboard 2.12.2\n","    Uninstalling tensorboard-2.12.2:\n","      Successfully uninstalled tensorboard-2.12.2\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","tensorflow-datasets 4.8.3 requires tensorflow-metadata, which is not installed.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed google-auth-oauthlib-0.4.6 keras-2.11.0 protobuf-3.19.6 tensorboard-2.11.2 tensorboard-data-server-0.6.1 tensorflow-2.11.1 tensorflow-estimator-2.11.0 tensorflow-text-2.11.0\n"]}]},{"cell_type":"code","source":["!pip install tensorflow-metadata==1.12.0"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3yhCknsD6pSu","executionInfo":{"status":"ok","timestamp":1683105923666,"user_tz":-330,"elapsed":5604,"user":{"displayName":"Joel Kunjachan Varghese","userId":"13276675938730244655"}},"outputId":"356cf63f-fe83-4cec-eff2-13a46ad747d2"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting tensorflow-metadata==1.12.0\n","  Downloading tensorflow_metadata-1.12.0-py3-none-any.whl (52 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.3/52.3 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: protobuf<4,>=3.13 in /usr/local/lib/python3.10/dist-packages (from tensorflow-metadata==1.12.0) (3.19.6)\n","Requirement already satisfied: absl-py<2.0.0,>=0.9 in /usr/local/lib/python3.10/dist-packages (from tensorflow-metadata==1.12.0) (1.4.0)\n","Requirement already satisfied: googleapis-common-protos<2,>=1.52.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-metadata==1.12.0) (1.59.0)\n","Installing collected packages: tensorflow-metadata\n","Successfully installed tensorflow-metadata-1.12.0\n"]}]},{"cell_type":"code","source":["!pip install tensorflow_datasets==4.8.2"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Vp2BNdKu6pQc","executionInfo":{"status":"ok","timestamp":1683105939798,"user_tz":-330,"elapsed":16134,"user":{"displayName":"Joel Kunjachan Varghese","userId":"13276675938730244655"}},"outputId":"79ea77c1-8b93-43b2-a0e1-3a64d025085d"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting tensorflow_datasets==4.8.2\n","  Downloading tensorflow_datasets-4.8.2-py3-none-any.whl (5.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.3/5.3 MB\u001b[0m \u001b[31m35.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: promise in /usr/local/lib/python3.10/dist-packages (from tensorflow_datasets==4.8.2) (2.3)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from tensorflow_datasets==4.8.2) (5.9.5)\n","Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from tensorflow_datasets==4.8.2) (1.4.0)\n","Requirement already satisfied: toml in /usr/local/lib/python3.10/dist-packages (from tensorflow_datasets==4.8.2) (0.10.2)\n","Requirement already satisfied: dm-tree in /usr/local/lib/python3.10/dist-packages (from tensorflow_datasets==4.8.2) (0.1.8)\n","Requirement already satisfied: etils[enp,epath]>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow_datasets==4.8.2) (1.2.0)\n","Requirement already satisfied: termcolor in /usr/local/lib/python3.10/dist-packages (from tensorflow_datasets==4.8.2) (2.3.0)\n","Collecting dill\n","  Downloading dill-0.3.6-py3-none-any.whl (110 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.5/110.5 kB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from tensorflow_datasets==4.8.2) (8.1.3)\n","Requirement already satisfied: protobuf>=3.12.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow_datasets==4.8.2) (3.19.6)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow_datasets==4.8.2) (2.27.1)\n","Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.10/dist-packages (from tensorflow_datasets==4.8.2) (1.12.0)\n","Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from tensorflow_datasets==4.8.2) (1.14.1)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from tensorflow_datasets==4.8.2) (4.65.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from tensorflow_datasets==4.8.2) (1.22.4)\n","Requirement already satisfied: zipp in /usr/local/lib/python3.10/dist-packages (from etils[enp,epath]>=0.9.0->tensorflow_datasets==4.8.2) (3.15.0)\n","Requirement already satisfied: importlib_resources in /usr/local/lib/python3.10/dist-packages (from etils[enp,epath]>=0.9.0->tensorflow_datasets==4.8.2) (5.12.0)\n","Requirement already satisfied: typing_extensions in /usr/local/lib/python3.10/dist-packages (from etils[enp,epath]>=0.9.0->tensorflow_datasets==4.8.2) (4.5.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->tensorflow_datasets==4.8.2) (2022.12.7)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->tensorflow_datasets==4.8.2) (1.26.15)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->tensorflow_datasets==4.8.2) (2.0.12)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->tensorflow_datasets==4.8.2) (3.4)\n","Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from promise->tensorflow_datasets==4.8.2) (1.16.0)\n","Requirement already satisfied: googleapis-common-protos<2,>=1.52.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-metadata->tensorflow_datasets==4.8.2) (1.59.0)\n","Installing collected packages: dill, tensorflow_datasets\n","  Attempting uninstall: tensorflow_datasets\n","    Found existing installation: tensorflow-datasets 4.8.3\n","    Uninstalling tensorflow-datasets-4.8.3:\n","      Successfully uninstalled tensorflow-datasets-4.8.3\n","Successfully installed dill-0.3.6 tensorflow_datasets-4.8.2\n"]}]},{"cell_type":"code","source":["!pip install einops"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"g0PrrXYl6pNn","executionInfo":{"status":"ok","timestamp":1683105949214,"user_tz":-330,"elapsed":9427,"user":{"displayName":"Joel Kunjachan Varghese","userId":"13276675938730244655"}},"outputId":"1be56a6e-f56f-4f5b-d3b6-f0128bf9df72"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting einops\n","  Downloading einops-0.6.1-py3-none-any.whl (42 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.2/42.2 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: einops\n","Successfully installed einops-0.6.1\n"]}]},{"cell_type":"code","source":["#@title\n","import concurrent.futures\n","import collections\n","import dataclasses\n","import hashlib\n","import itertools\n","import json\n","import math\n","import os\n","import pathlib\n","import random\n","import re\n","import string\n","import time\n","import urllib.request\n","\n","import einops\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import pandas as pd\n","from PIL import Image\n","import requests\n","import tqdm\n","\n","import tensorflow as tf\n","import tensorflow_hub as hub\n","import tensorflow_text as text\n","import tensorflow_datasets as tfds"],"metadata":{"id":"qzhzNGmt6pLi","executionInfo":{"status":"ok","timestamp":1683105954149,"user_tz":-330,"elapsed":4939,"user":{"displayName":"Joel Kunjachan Varghese","userId":"13276675938730244655"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["def load_image(image_path):\n","    img = tf.io.read_file(image_path)\n","    img = tf.io.decode_jpeg(img, channels=3)\n","    img = tf.image.resize(img, IMAGE_SHAPE[:-1])\n","    return img"],"metadata":{"id":"cdFv8mmf6pJT","executionInfo":{"status":"ok","timestamp":1683105954149,"user_tz":-330,"elapsed":4,"user":{"displayName":"Joel Kunjachan Varghese","userId":"13276675938730244655"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"jfBBAOLz8D_6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"QBPQoeBi8D8X"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["IMAGE_SHAPE=(224, 224, 3)\n","mobilenet = tf.keras.applications.MobileNetV3Small(\n","    input_shape=IMAGE_SHAPE,\n","    include_top=False,\n","    include_preprocessing=True)\n","mobilenet.trainable=False"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"d3yb_06B8D6J","executionInfo":{"status":"ok","timestamp":1683106216471,"user_tz":-330,"elapsed":4442,"user":{"displayName":"Joel Kunjachan Varghese","userId":"13276675938730244655"}},"outputId":"1f3c24be-8ccc-4ee1-d93f-93ab0fae1601"},"execution_count":23,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v3/weights_mobilenet_v3_small_224_1.0_float_no_top_v2.h5\n","4334752/4334752 [==============================] - 0s 0us/step\n"]}]},{"cell_type":"code","source":["def standardize(s):\n","  s = tf.strings.lower(s)\n","  s = tf.strings.regex_replace(s, f'[{re.escape(string.punctuation)}]', '')\n","  s = tf.strings.join(['[START]', s, '[END]'], separator=' ')\n","  return s"],"metadata":{"id":"blj7FJsQ8D4M","executionInfo":{"status":"ok","timestamp":1683106179148,"user_tz":-330,"elapsed":378,"user":{"displayName":"Joel Kunjachan Varghese","userId":"13276675938730244655"}}},"execution_count":20,"outputs":[]},{"cell_type":"code","source":["# Use the top 5000 words for a vocabulary.\n","vocabulary_size = 5000\n","tokenizer = tf.keras.layers.TextVectorization(\n","    max_tokens=vocabulary_size,\n","    standardize=standardize,\n","    ragged=True)\n","# Learn the vocabulary from the caption data."],"metadata":{"id":"A8yvQxbW6Gxq","executionInfo":{"status":"ok","timestamp":1683106184933,"user_tz":-330,"elapsed":995,"user":{"displayName":"Joel Kunjachan Varghese","userId":"13276675938730244655"}}},"execution_count":21,"outputs":[]},{"cell_type":"code","source":["#@title\n","class TokenOutput(tf.keras.layers.Layer):\n","  def __init__(self, tokenizer, banned_tokens=('', '[UNK]', '[START]'), **kwargs):\n","    super().__init__()\n","    \n","    self.dense = tf.keras.layers.Dense(\n","        units=tokenizer.vocabulary_size(), **kwargs)\n","    self.tokenizer = tokenizer\n","    self.banned_tokens = banned_tokens\n","\n","    self.bias = None\n","\n","  def adapt(self, ds):\n","    counts = collections.Counter()\n","    vocab_dict = {name: id \n","                  for id, name in enumerate(self.tokenizer.get_vocabulary())}\n","\n","    for tokens in tqdm.tqdm(ds):\n","      counts.update(tokens.numpy().flatten())\n","\n","    counts_arr = np.zeros(shape=(self.tokenizer.vocabulary_size(),))\n","    counts_arr[np.array(list(counts.keys()), dtype=np.int32)] = list(counts.values())\n","\n","    counts_arr = counts_arr[:]\n","    for token in self.banned_tokens:\n","      counts_arr[vocab_dict[token]] = 0\n","\n","    total = counts_arr.sum()\n","    p = counts_arr/total\n","    p[counts_arr==0] = 1.0\n","    log_p = np.log(p)  # log(1) == 0\n","\n","    entropy = -(log_p*p).sum()\n","\n","    print()\n","    print(f\"Uniform entropy: {np.log(self.tokenizer.vocabulary_size()):0.2f}\")\n","    print(f\"Marginal entropy: {entropy:0.2f}\")\n","\n","    self.bias = log_p\n","    self.bias[counts_arr==0] = -1e9\n","\n","  def call(self, x):\n","    x = self.dense(x)\n","    # TODO(b/250038731): Fix this.\n","    # An Add layer doesn't work because of the different shapes.\n","    # This clears the mask, that's okay because it prevents keras from rescaling\n","    # the losses.\n","    return x + self.bias\n"],"metadata":{"id":"ryySVIbB9KYh","executionInfo":{"status":"ok","timestamp":1683106347385,"user_tz":-330,"elapsed":421,"user":{"displayName":"Joel Kunjachan Varghese","userId":"13276675938730244655"}}},"execution_count":26,"outputs":[]},{"cell_type":"code","source":["output_layer = TokenOutput(tokenizer, banned_tokens=('', '[UNK]', '[START]'))\n","# This might run a little faster if the dataset didn't also have to load the image data.\n","output_layer.adapt(train_ds.map(lambda inputs, labels: labels))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":200},"id":"DYrfqWEx9BZS","executionInfo":{"status":"error","timestamp":1683106354189,"user_tz":-330,"elapsed":4,"user":{"displayName":"Joel Kunjachan Varghese","userId":"13276675938730244655"}},"outputId":"54a779fd-0dcd-43cf-ef53-f07389baccf4"},"execution_count":27,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-27-116adaf481ee>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0moutput_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTokenOutput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbanned_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'[UNK]'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'[START]'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# This might run a little faster if the dataset didn't also have to load the image data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0moutput_layer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madapt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_ds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'train_ds' is not defined"]}]},{"cell_type":"code","source":["class Captioner(tf.keras.Model):\n","  @classmethod\n","  def add_method(cls, fun):\n","    setattr(cls, fun.__name__, fun)\n","    return fun\n","\n","  def __init__(self, tokenizer, feature_extractor, output_layer, num_layers=1,\n","               units=256, max_length=50, num_heads=1, dropout_rate=0.1):\n","    super().__init__()\n","    self.feature_extractor = feature_extractor\n","    self.tokenizer = tokenizer\n","    self.word_to_index = tf.keras.layers.StringLookup(\n","        mask_token=\"\",\n","        vocabulary=tokenizer.get_vocabulary())\n","    self.index_to_word = tf.keras.layers.StringLookup(\n","        mask_token=\"\",\n","        vocabulary=tokenizer.get_vocabulary(),\n","        invert=True) \n","\n","    self.seq_embedding = SeqEmbedding(\n","        vocab_size=tokenizer.vocabulary_size(),\n","        depth=units,\n","        max_length=max_length)\n","\n","    self.decoder_layers = [\n","        DecoderLayer(units, num_heads=num_heads, dropout_rate=dropout_rate)\n","        for n in range(num_layers)]\n","\n","    self.output_layer = output_layer"],"metadata":{"id":"ecsRpFx87fbz","executionInfo":{"status":"ok","timestamp":1683106060162,"user_tz":-330,"elapsed":360,"user":{"displayName":"Joel Kunjachan Varghese","userId":"13276675938730244655"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["@Captioner.add_method\n","def call(self, inputs):\n","    image, txt = inputs\n","\n","    if image.shape[-1] == 3:\n","      # Apply the feature-extractor, if you get an RGB image.\n","      image = self.feature_extractor(image)\n","    \n","    # Flatten the feature map\n","    image = einops.rearrange(image, 'b h w c -> b (h w) c')\n","\n","\n","    if txt.dtype == tf.string:\n","      # Apply the tokenizer if you get string inputs.\n","      txt = tokenizer(txt)\n","\n","    txt = self.seq_embedding(txt)\n","\n","    # Look at the image\n","    for dec_layer in self.decoder_layers:\n","      txt = dec_layer(inputs=(image, txt))\n","      \n","    txt = self.output_layer(txt)\n","\n","    return txt"],"metadata":{"id":"WfKGF7Kj7fYb","executionInfo":{"status":"ok","timestamp":1683106064307,"user_tz":-330,"elapsed":2,"user":{"displayName":"Joel Kunjachan Varghese","userId":"13276675938730244655"}}},"execution_count":16,"outputs":[]},{"cell_type":"code","source":["model = Captioner(tokenizer, feature_extractor=mobilenet, output_layer=output_layer,\n","                  units=256, dropout_rate=0.5, num_layers=2, num_heads=2)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":183},"id":"zjECSe4N7fWV","executionInfo":{"status":"error","timestamp":1683106227260,"user_tz":-330,"elapsed":3,"user":{"displayName":"Joel Kunjachan Varghese","userId":"13276675938730244655"}},"outputId":"d08541f4-e8c4-4b4f-94d6-cf3f55890349"},"execution_count":24,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-24-0b2596a3ba31>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m model = Captioner(tokenizer, feature_extractor=mobilenet, output_layer=output_layer,\n\u001b[0m\u001b[1;32m      2\u001b[0m                   units=256, dropout_rate=0.5, num_layers=2, num_heads=2)\n","\u001b[0;31mNameError\u001b[0m: name 'output_layer' is not defined"]}]},{"cell_type":"code","source":["model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n","           loss=masked_loss,\n","           metrics=[masked_acc])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":200},"id":"UwLdAhaG7fUQ","executionInfo":{"status":"error","timestamp":1683105960253,"user_tz":-330,"elapsed":715,"user":{"displayName":"Joel Kunjachan Varghese","userId":"13276675938730244655"}},"outputId":"103b46cc-6b53-497a-b2cd-32f0e8ea4fa3"},"execution_count":11,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-11-545ba1391228>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n\u001b[0m\u001b[1;32m      2\u001b[0m            \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmasked_loss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m            metrics=[masked_acc])\n","\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"]}]},{"cell_type":"code","source":[],"metadata":{"id":"hmIy9Agf7fSU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"RlyD0BqX7fQT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"xu5xUFfh7fOW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"qm2ijpIx7fMf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["@Captioner.add_method\n","def run_and_show_attention(self, image, temperature=0.0):\n","  result_txt = self.simple_gen(image, temperature)\n","  str_tokens = result_txt.split()\n","  str_tokens.append('[END]')\n","\n","  attention_maps = [layer.last_attention_scores for layer in self.decoder_layers]\n","  attention_maps = tf.concat(attention_maps, axis=0)\n","  attention_maps = einops.reduce(\n","      attention_maps,\n","      'batch heads sequence (height width) -> sequence height width',\n","      height=7, width=7,\n","      reduction='mean')\n","  \n","  plot_attention_maps(image/255, str_tokens, attention_maps)\n","  t = plt.suptitle(result_txt)\n","  t.set_y(1.05)"],"metadata":{"id":"i-AsqBTY6Gvv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["image_url = 'https://tensorflow.org/images/bedroom_hrnet_tutorial.jpg'\n","image_path = tf.keras.utils.get_file(origin=image_url)\n","image = load_image(image_path)\n","\n","run_and_show_attention(model, image)"],"metadata":{"id":"pQhavTbZ6Gte"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"6DQ-Xm8Y6GrJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"BUFxmYEv6Go9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"ZuUcmYlW6Gmn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"_cpJ-MBi6GkR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"dMrz6UTj6GiC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"G_jt4FH86Gfm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"MddGOUW_6GdX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"9DZMyCjt6GbK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"hJjGqz_U6GY6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"27GLuBPt6GWu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"YMyTnjfr6GU4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"D-mhnKK26GSp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"WNPzoD9Z6GQk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"zKPVYGPL6GOV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"p8GcoVIz6GMH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"022lGO6O6GJ6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"IFyTT1iY6GH0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"AJAwxkWs6GF2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"XYeRXnbH6GDw"},"execution_count":null,"outputs":[]}]}